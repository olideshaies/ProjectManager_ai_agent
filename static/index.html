<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Voice Command Client</title>
  <style>
    /* Basic styling for the conversation container */
    .conversation-container {
      max-width: 800px;
      margin: 20px auto;
      padding: 20px;
      border: 1px solid #ccc;
      border-radius: 5px;
      max-height: 500px;
      overflow-y: auto;
    }
    
    .message {
      margin: 10px 0;
      padding: 10px;
      border-radius: 5px;
    }
    
    .user-message {
      background-color: #e3f2fd;
      margin-left: 20%;
    }
    
    .system-message {
      background-color: #f5f5f5;
      margin-right: 20%;
    }
    
    .timestamp {
      font-size: 0.8em;
      color: #666;
      margin-bottom: 5px;
    }
  </style>
</head>
<body>
  <h1>Voice Command Client</h1>
  <button id="record">Record Command</button>
  <button id="stop" disabled>Stop Recording</button>
  <p id="status"></p>
  
  <!-- New conversation history container -->
  <div class="conversation-container" id="conversationHistory"></div>

  <script>
    let mediaRecorder;
    let audioChunks = [];
    let conversationHistory = [];

    // Function to add a message to the conversation history
    function addMessageToHistory(type, content) {
      const timestamp = new Date().toLocaleTimeString();
      const messageDiv = document.createElement('div');
      messageDiv.className = `message ${type}-message`;
      
      const timestampSpan = document.createElement('div');
      timestampSpan.className = 'timestamp';
      timestampSpan.textContent = timestamp;
      
      const contentDiv = document.createElement('div');
      contentDiv.textContent = content;
      
      messageDiv.appendChild(timestampSpan);
      messageDiv.appendChild(contentDiv);
      
      document.getElementById('conversationHistory').appendChild(messageDiv);
      // Scroll to the bottom of the conversation
      messageDiv.scrollIntoView({ behavior: 'smooth' });
      
      // Store in history array
      conversationHistory.push({ type, content, timestamp });
    }

    // Start recording when the user clicks the "Record Command" button.
    document.getElementById('record').addEventListener('click', async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        // Optional: Check if 'audio/wav' is supported.
        if (!MediaRecorder.isTypeSupported("audio/wav")) {
          console.warn("audio/wav not supported; using default MIME type.");
        }
        mediaRecorder = new MediaRecorder(stream);
        mediaRecorder.start();
        console.log("Recording started.");
        document.getElementById('status').innerText = 'Recording...';
        document.getElementById('record').disabled = true;
        document.getElementById('stop').disabled = false;
        
        mediaRecorder.addEventListener('dataavailable', event => {
          if (event.data && event.data.size > 0) {
            console.log("Received audio data chunk:", event.data);
            audioChunks.push(event.data);
          } else {
            console.log("No audio data received in this chunk.");
          }
        });

        mediaRecorder.addEventListener('stop', async () => {
          // Create a Blob from the recorded audio.
          const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
          console.log("Audio blob created, size:", audioBlob.size);
          // Reset the audio chunks for the next recording.
          audioChunks = [];
          
          // Prepare the form data to send to your FastAPI endpoint.
          const formData = new FormData();
          formData.append('audio_file', audioBlob, 'voice_command.wav');

          document.getElementById('status').innerText = 'Uploading audio...';
          try {
            const response = await fetch('http://localhost:8000/voice/command', {
              method: 'POST',
              body: formData
            });
            const result = await response.json();
            console.log("Server response:", result);
            
            // Add user's transcription to history
            addMessageToHistory('user', `Command: ${result.transcription}`);
            
            // Add system's response to history
            addMessageToHistory('system', `Response: ${result.message}`);
            
            document.getElementById('status').innerText = 'Command processed successfully';
          } catch (error) {
            console.error("Error during fetch:", error);
            document.getElementById('status').innerText = 'Error: ' + error;
            addMessageToHistory('system', `Error: ${error.message}`);
          }
          document.getElementById('record').disabled = false;
          document.getElementById('stop').disabled = true;
        });
      } catch (error) {
        console.error("Error accessing microphone:", error);
        document.getElementById('status').innerText = 'Error accessing microphone: ' + error;
        addMessageToHistory('system', `Error accessing microphone: ${error.message}`);
      }
    });

    // Stop recording when the user clicks the "Stop Recording" button.
    document.getElementById('stop').addEventListener('click', () => {
      if (mediaRecorder) {
        mediaRecorder.stop();
        console.log("Recording stopped.");
        document.getElementById('status').innerText = 'Stopped recording.';
      }
    });
  </script>
</body>
</html>
